{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 코랩 설정\n",
        "\n",
        "아래 순서에 따라 코랩 환경을 설정합니다. \n",
        "1. 메뉴 > 런타임 > 런타임 유형 변경에서 \"GPU\"를 선택합니다.\n",
        "\n",
        "아래 명령으로 data 폴더를 생성합니다."
      ],
      "metadata": {
        "id": "s9H3JKCwiJ04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "id": "oBcNU47_-TV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터셋 가져오기\n",
        "\n",
        "아래 코드를 통해 데이터셋을 다운로드 받습니다."
      ],
      "metadata": {
        "id": "RZnjwz9jhkWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -d '[{\"originFilename\":\"qm9_train_data.pt\",\"convertFilename\":\"20220919004741_QbYk.pt\"}]' -H \"Content-Type: application/json\" -X POST https://cdn.aifactory.space/download/additionalFiles -o ./data/qm9_train_data.pt\n",
        "!curl -d '[{\"originFilename\":\"qm9_test_data.pt\",\"convertFilename\":\"20220919004756_XrdQ.pt\"}]' -H \"Content-Type: application/json\" -X POST https://cdn.aifactory.space/download/additionalFiles -o ./data/qm9_test_data.pt"
      ],
      "metadata": {
        "id": "naYTU609-bbV",
        "outputId": "c8227fa1-606a-4bca-838e-d5d24de50a61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 93.7M  100 93.7M  100    83  28.3M     25  0:00:03  0:00:03 --:--:-- 28.3M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 30.8M  100 30.8M  100    82  19.5M     51  0:00:01  0:00:01 --:--:-- 19.5M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 베이스라인 코드 구동에 필요한 파일다운로드"
      ],
      "metadata": {
        "id": "4DXXb4ZLWxST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/aifactory-team/AFCompetition/master/2106/gnn.yaml\n",
        "!wget https://raw.githubusercontent.com/aifactory-team/AFCompetition/master/2106/qm9_dataset.py\n",
        "!wget https://raw.githubusercontent.com/aifactory-team/AFCompetition/master/2106/model.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6rB08_DT4Gt",
        "outputId": "6f9b118e-8ad3-497d-e7af-1b03d7861dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-20 08:21:34--  https://raw.githubusercontent.com/aifactory-team/AFCompetition/master/2106/gnn.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 454 [text/plain]\n",
            "Saving to: ‘gnn.yaml’\n",
            "\n",
            "\rgnn.yaml              0%[                    ]       0  --.-KB/s               \rgnn.yaml            100%[===================>]     454  --.-KB/s    in 0s      \n",
            "\n",
            "2022-09-20 08:21:34 (32.1 MB/s) - ‘gnn.yaml’ saved [454/454]\n",
            "\n",
            "--2022-09-20 08:21:34--  https://raw.githubusercontent.com/aifactory-team/AFCompetition/master/2106/qm9_dataset.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7680 (7.5K) [text/plain]\n",
            "Saving to: ‘qm9_dataset.py’\n",
            "\n",
            "qm9_dataset.py      100%[===================>]   7.50K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-09-20 08:21:35 (76.8 MB/s) - ‘qm9_dataset.py’ saved [7680/7680]\n",
            "\n",
            "--2022-09-20 08:21:35--  https://raw.githubusercontent.com/aifactory-team/AFCompetition/master/2106/model.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2021 (2.0K) [text/plain]\n",
            "Saving to: ‘model.py’\n",
            "\n",
            "model.py            100%[===================>]   1.97K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-09-20 08:21:35 (45.0 MB/s) - ‘model.py’ saved [2021/2021]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 베이스라인 구동에 필요한 패키지 설치\n",
        "\n",
        "dgl 패키지를 설치하기 위해 현재 코랩의 파이썬 버전 및 cuda 버전을 확인합니다."
      ],
      "metadata": {
        "id": "PphCxfgAW499"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.version)\n",
        "\n",
        "import torch\n",
        "\n",
        "print(\"Torch version:{}\".format(torch.__version__))\n",
        "print(\"cuda version: {}\".format(torch.version.cuda))\n",
        "print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xf-qZRR9aQLo",
        "outputId": "a57c84b5-1b53-4808-e448-d51f1344a1e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7.14 (default, Sep  8 2022, 00:06:44) \n",
            "[GCC 7.5.0]\n",
            "Torch version:1.12.1+cu113\n",
            "cuda version: 11.3\n",
            "cudnn version:8302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.dgl.ai/pages/start.html 에 접속해서 파이썬 및 코랩 버전에 해당하는 설치 명령을 복사합니다."
      ],
      "metadata": {
        "id": "xCkWBqLUi_YH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl-cu113 dglgo -f https://data.dgl.ai/wheels/repo.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wDC3DQ4zgmFi",
        "outputId": "69e2f8ed-f094-499b-d8ea-32b4af036022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.dgl.ai/wheels/repo.html\n",
            "Collecting dgl-cu113\n",
            "  Downloading https://data.dgl.ai/wheels/dgl_cu113-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (239.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 239.1 MB 18 kB/s \n",
            "\u001b[?25hCollecting dglgo\n",
            "  Downloading dglgo-0.0.2-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from dgl-cu113) (4.64.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu113) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu113) (1.7.3)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl-cu113) (2.6.3)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.9.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[K     |████████████████████████████████| 281 kB 61.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu113) (1.21.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu113) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu113) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu113) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu113) (3.0.4)\n",
            "Collecting isort>=5.10.1\n",
            "  Downloading isort-5.10.1-py3-none-any.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 51.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from dglgo) (1.9.2)\n",
            "Collecting ruamel.yaml>=0.17.20\n",
            "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 64.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from dglgo) (1.0.2)\n",
            "Requirement already satisfied: typer>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from dglgo) (0.4.2)\n",
            "Collecting ogb>=1.3.3\n",
            "  Downloading ogb-1.3.4-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/dist-packages (from dglgo) (6.0)\n",
            "Collecting rdkit-pypi\n",
            "  Downloading rdkit_pypi-2022.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 36.8 MB 39 kB/s \n",
            "\u001b[?25hCollecting numpydoc>=1.1.0\n",
            "  Downloading numpydoc-1.4.0-py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 694 kB/s \n",
            "\u001b[?25hCollecting autopep8>=1.6.0\n",
            "  Downloading autopep8-1.7.0-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from autopep8>=1.6.0->dglgo) (0.10.2)\n",
            "Collecting pycodestyle>=2.9.1\n",
            "  Downloading pycodestyle-2.9.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 482 kB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.7/dist-packages (from numpydoc>=1.1.0->dglgo) (2.11.3)\n",
            "Collecting sphinx>=3.0\n",
            "  Downloading Sphinx-5.1.1-py3-none-any.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 54.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.0.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from ogb>=1.3.3->dglgo) (1.15.0)\n",
            "Collecting outdated>=0.2.0\n",
            "  Downloading outdated-0.2.1-py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb>=1.3.3->dglgo) (1.3.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from ogb>=1.3.3->dglgo) (1.12.1+cu113)\n",
            "Collecting littleutils\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2022.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic>=1.9.0->dglgo) (4.1.1)\n",
            "Collecting ruamel.yaml.clib>=0.2.6\n",
            "  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n",
            "\u001b[K     |████████████████████████████████| 546 kB 68.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->dglgo) (3.1.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (0.7.12)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (4.12.0)\n",
            "Collecting sphinxcontrib-devhelp\n",
            "  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting sphinxcontrib-applehelp\n",
            "  Downloading sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[K     |████████████████████████████████| 121 kB 76.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docutils<0.20,>=0.14 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (0.17.1)\n",
            "Collecting sphinxcontrib-qthelp\n",
            "  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 12.0 MB/s \n",
            "\u001b[?25hCollecting sphinxcontrib-jsmath\n",
            "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2.10.3)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (1.4.1)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2.6.1)\n",
            "Collecting sphinxcontrib-htmlhelp>=2.0.0\n",
            "  Downloading sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (21.3)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (1.1.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->sphinx>=3.0->numpydoc>=1.1.0->dglgo) (3.8.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer>=0.4.0->dglgo) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->sphinx>=3.0->numpydoc>=1.1.0->dglgo) (3.0.9)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from rdkit-pypi->dglgo) (7.1.2)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=84078454275310fc2f2bf867632f7756926f11769eeab9e4dd489e731d09d468\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/64/cd/32819b511a488e4993f2fab909a95330289c3f4e0f6ef4676d\n",
            "Successfully built littleutils\n",
            "Installing collected packages: sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, littleutils, sphinx, ruamel.yaml.clib, pycodestyle, outdated, ruamel.yaml, rdkit-pypi, psutil, ogb, numpydoc, isort, autopep8, dglgo, dgl-cu113\n",
            "  Attempting uninstall: sphinx\n",
            "    Found existing installation: Sphinx 1.8.6\n",
            "    Uninstalling Sphinx-1.8.6:\n",
            "      Successfully uninstalled Sphinx-1.8.6\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed autopep8-1.7.0 dgl-cu113-0.9.1 dglgo-0.0.2 isort-5.10.1 littleutils-0.2.2 numpydoc-1.4.0 ogb-1.3.4 outdated-0.2.1 psutil-5.9.2 pycodestyle-2.9.1 rdkit-pypi-2022.3.5 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.6 sphinx-5.1.1 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil",
                  "sphinxcontrib"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install omegaconf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OffRlHGEVg8N",
        "outputId": "307de54e-6ca4-4002-f702-9d0604414ecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.7/dist-packages (2.2.3)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.7/dist-packages (from omegaconf) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf) (6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 베이스라인 코드 실행 및 제출 결과 파일 생성"
      ],
      "metadata": {
        "id": "zvcIfT8AW8Ss"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNdZvZ0nTO0D",
        "outputId": "e868a178-f410-451b-ec37-c77abc1652eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "cuda available with GPU: Tesla T4\n",
            "Loaded train-set, task: mu, source: ./data/, length: 98123\n",
            "Loaded test-set, task: mu, source: ./data/, length: 32708\n",
            "Train set size: 78498\n",
            "Validation set size: 19625\n",
            "Test set size: 32708\n",
            "Begin training\n",
            "[0|0] loss: 2.65366\n",
            "[0|5] loss: 2.18377\n",
            "[0|10] loss: 1.65425\n",
            "[0|15] loss: 1.22601\n",
            "[0|20] loss: 1.46055\n",
            "[0|25] loss: 1.19969\n",
            "[0|30] loss: 1.13633\n",
            "[0|35] loss: 1.32136\n",
            "[0|40] loss: 1.21862\n",
            "[0|45] loss: 1.06600\n",
            "[0|50] loss: 1.17025\n",
            "[0|55] loss: 1.21068\n",
            "[0|60] loss: 1.13126\n",
            "[0|65] loss: 1.15721\n",
            "[0|70] loss: 1.04274\n",
            "[0|75] loss: 1.05481\n",
            "[0|80] loss: 0.93207\n",
            "[0|85] loss: 1.09956\n",
            "[0|90] loss: 1.08441\n",
            "[0|95] loss: 1.05560\n",
            "[0|100] loss: 1.09095\n",
            "[0|105] loss: 1.06502\n",
            "[0|110] loss: 1.08098\n",
            "[0|115] loss: 1.05590\n",
            "[0|120] loss: 1.03363\n",
            "[0|125] loss: 1.15154\n",
            "[0|130] loss: 1.14658\n",
            "[0|135] loss: 0.97789\n",
            "[0|140] loss: 1.18086\n",
            "[0|145] loss: 0.98820\n",
            "[0|150] loss: 1.01575\n",
            "[0|155] loss: 0.88845\n",
            "[0|160] loss: 1.07723\n",
            "[0|165] loss: 1.08520\n",
            "[0|170] loss: 1.03632\n",
            "[0|175] loss: 1.00173\n",
            "[0|180] loss: 1.07546\n",
            "[0|185] loss: 1.04029\n",
            "[0|190] loss: 0.98369\n",
            "[0|195] loss: 1.06974\n",
            "[0|200] loss: 1.04512\n",
            "[0|205] loss: 0.97620\n",
            "[0|210] loss: 1.08350\n",
            "[0|215] loss: 0.94429\n",
            "[0|220] loss: 1.08048\n",
            "[0|225] loss: 1.03040\n",
            "[0|230] loss: 1.00492\n",
            "[0|235] loss: 0.95811\n",
            "[0|240] loss: 1.10609\n",
            "[0|245] loss: 1.01703\n",
            "[0|250] loss: 1.04169\n",
            "[0|255] loss: 0.84421\n",
            "[0|260] loss: 1.08621\n",
            "[0|265] loss: 1.12456\n",
            "[0|270] loss: 0.84208\n",
            "[0|275] loss: 1.06040\n",
            "[0|280] loss: 1.07081\n",
            "[0|285] loss: 0.85529\n",
            "[0|290] loss: 0.99669\n",
            "[0|295] loss: 0.97565\n",
            "[0|300] loss: 1.06673\n",
            "[0|305] loss: 0.91179\n",
            "[0|310] loss: 0.99563\n",
            "[0|315] loss: 1.02260\n",
            "[0|320] loss: 0.98542\n",
            "[0|325] loss: 0.96032\n",
            "[0|330] loss: 1.20960\n",
            "[0|335] loss: 1.09170\n",
            "[0|340] loss: 0.97943\n",
            "[0|345] loss: 1.01909\n",
            "[0|350] loss: 1.09618\n",
            "[0|355] loss: 0.81519\n",
            "[0|360] loss: 0.84679\n",
            "[0|365] loss: 0.92520\n",
            "[0|370] loss: 0.90729\n",
            "[0|375] loss: 1.23545\n",
            "[0|380] loss: 1.00864\n",
            "[0|385] loss: 1.02285\n",
            "[0|390] loss: 0.95139\n",
            "[0|395] loss: 1.08772\n",
            "[0|400] loss: 1.10196\n",
            "[0|405] loss: 0.94199\n",
            "[0|410] loss: 1.03565\n",
            "[0|415] loss: 1.06071\n",
            "[0|420] loss: 1.02270\n",
            "[0|425] loss: 1.07491\n",
            "[0|430] loss: 1.00260\n",
            "[0|435] loss: 1.04691\n",
            "[0|440] loss: 1.01350\n",
            "[0|445] loss: 0.86105\n",
            "[0|450] loss: 0.98010\n",
            "[0|455] loss: 1.24013\n",
            "[0|460] loss: 0.93815\n",
            "[0|465] loss: 0.99273\n",
            "[0|470] loss: 0.99038\n",
            "[0|475] loss: 0.98027\n",
            "[0|480] loss: 1.11446\n",
            "[0|485] loss: 0.91604\n",
            "[0|490] loss: 1.07869\n",
            "[0|495] loss: 0.96982\n",
            "[0|500] loss: 0.95799\n",
            "[0|505] loss: 1.16844\n",
            "[0|510] loss: 0.93004\n",
            "[0|515] loss: 1.04660\n",
            "[0|520] loss: 1.15313\n",
            "[0|525] loss: 1.03904\n",
            "[0|530] loss: 0.93050\n",
            "[0|535] loss: 0.97300\n",
            "[0|540] loss: 1.06901\n",
            "[0|545] loss: 0.81798\n",
            "[0|550] loss: 0.97585\n",
            "[0|555] loss: 1.04298\n",
            "[0|560] loss: 0.98148\n",
            "[0|565] loss: 0.85887\n",
            "[0|570] loss: 0.98053\n",
            "[0|575] loss: 0.91951\n",
            "[0|580] loss: 0.98471\n",
            "[0|585] loss: 0.99522\n",
            "[0|590] loss: 0.92637\n",
            "[0|595] loss: 0.88226\n",
            "[0|600] loss: 0.89451\n",
            "[0|605] loss: 0.86859\n",
            "[0|610] loss: 0.82529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 154/154 [00:09<00:00, 15.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...[0|val] loss: 148.51277\n",
            "Saved checkpoint: ./results/GNN_model_mu_0.pt\n",
            "Begin test\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 256/256 [00:15<00:00, 16.37it/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import argparse\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from qm9_dataset import QM9DGLDataset\n",
        "from omegaconf import OmegaConf\n",
        "from model import GNN_model\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "\"\"\"\n",
        "    GPU Setup\n",
        "\"\"\"\n",
        "def gpu_setup(use_gpu, gpu_id):\n",
        "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
        "\n",
        "    if torch.cuda.is_available() and use_gpu:\n",
        "        print('cuda available with GPU:',torch.cuda.get_device_name(0))\n",
        "        device = torch.device(\"cuda\")\n",
        "    else:\n",
        "        print('cuda not available')\n",
        "        device = torch.device(\"cpu\")\n",
        "    return device\n",
        "\n",
        "\n",
        "def to_np(x):\n",
        "    return x.cpu().detach().numpy()\n",
        "\n",
        "\n",
        "def train_epoch(epoch, model, loss_fnc, dataloader, optimizer, scheduler, FLAGS, device):\n",
        "    model.train()\n",
        "    num_iters = len(dataloader)\n",
        "    for i, (g, y) in enumerate(dataloader):\n",
        "        g = g.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # run model forward and compute loss\n",
        "        pred = model(g)\n",
        "        loss = loss_fnc(pred, y)\n",
        "\n",
        "        # backprop\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % FLAGS.train_params.print_epoch_interval == 0:\n",
        "            print(f\"[{epoch}|{i}] loss: {loss.item():.5f}\")\n",
        "\n",
        "        scheduler.step(epoch + i / num_iters)\n",
        "\n",
        "\n",
        "def val_epoch(epoch, model, loss_fnc, dataloader, FLAGS, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    rescale_loss = 0\n",
        "    for i, (g, y) in enumerate(tqdm(dataloader)):\n",
        "        g = g.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # run model forward and compute loss\n",
        "        pred = model(g)\n",
        "        loss = loss_fnc(pred, y)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"...[{epoch}|val] loss: {total_loss:.5f}\")\n",
        "\n",
        "\n",
        "def run_test(model, dataloader, device):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    for g in tqdm(dataloader):\n",
        "        g = g.to(device)\n",
        "        pred = model(g)\n",
        "        preds.append(to_np(pred))\n",
        "\n",
        "    return np.concatenate(preds, axis=0)\n",
        "\n",
        "# Loss function\n",
        "def l1_loss(pred, target):\n",
        "    loss = F.l1_loss(pred, target)\n",
        "    return loss\n",
        "\n",
        "################ 1. parsing arguments\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--config', type=str, default='./gnn.yaml', help='configration for model')\n",
        "parser.add_argument('--pretrained_path', type=str, default=None, help='configration for model')\n",
        "args, extra_args = parser.parse_known_args()\n",
        "FLAGS = OmegaConf.load(args.config)\n",
        "\n",
        "# Create model directory\n",
        "if not os.path.isdir(FLAGS.out_dir):\n",
        "    os.makedirs(FLAGS.out_dir)\n",
        "\n",
        "# Fix SEED\n",
        "torch.manual_seed(FLAGS.train_params.seed)\n",
        "np.random.seed(FLAGS.train_params.seed)\n",
        "\n",
        "# Automatically choose GPU if available\n",
        "device = gpu_setup(FLAGS['gpu']['use'], FLAGS['gpu']['id'])\n",
        "\n",
        "\n",
        "\n",
        "################ 2. Prepare data\n",
        "dataset = QM9DGLDataset(FLAGS.data_path,\n",
        "                              FLAGS.task,\n",
        "                              file_name='qm9_train_data.pt',\n",
        "                              mode='train')\n",
        "\n",
        "train_dataset, val_dataset = dataset.train_val_random_split(0.8)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size=FLAGS.train_params.batch_size,\n",
        "                          shuffle=True,\n",
        "                          collate_fn=dataset.collate_fn,\n",
        "                          num_workers=FLAGS.data.num_workers)\n",
        "\n",
        "val_loader = DataLoader(val_dataset,\n",
        "                        batch_size=FLAGS.train_params.batch_size,\n",
        "                        shuffle=False,\n",
        "                        collate_fn=dataset.collate_fn,\n",
        "                        num_workers=FLAGS.data.num_workers)\n",
        "\n",
        "# Test Dataset\n",
        "test_dataset = QM9DGLDataset(FLAGS.data_path,\n",
        "                         FLAGS.task,\n",
        "                         file_name='qm9_test_data.pt',\n",
        "                         mode='test')\n",
        "\n",
        "test_loader = DataLoader(test_dataset,\n",
        "                         batch_size=FLAGS.train_params.batch_size,\n",
        "                         shuffle=False,\n",
        "                         collate_fn=test_dataset.collate_fn,\n",
        "                         num_workers=FLAGS.data.num_workers)\n",
        "\n",
        "FLAGS.train_size = len(train_dataset)\n",
        "FLAGS.val_size = len(val_dataset)\n",
        "FLAGS.test_size = len(test_dataset)\n",
        "print(f\"Train set size: {len(train_dataset)}\")\n",
        "print(f\"Validation set size: {len(val_dataset)}\")\n",
        "print(f\"Test set size: {len(test_dataset)}\")\n",
        "\n",
        "################ 2. Prepare model\n",
        "model = GNN_model(FLAGS.graph_encoder_params)\n",
        "\n",
        "if args.pretrained_path is not None:\n",
        "    model.load_state_dict(torch.load(args.pretrained_path))\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "criterion = l1_loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=FLAGS.train_params.init_lr)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer,\n",
        "                                                           FLAGS.train_params.epochs,\n",
        "                                                           eta_min=FLAGS.train_params.min_lr)\n",
        "                                                 \n",
        "\n",
        "################ 2. Start training\n",
        "\n",
        "# Run training\n",
        "print('Begin training')\n",
        "for epoch in range(FLAGS.train_params.epochs):\n",
        "    train_epoch(epoch, model, criterion, train_loader, optimizer, scheduler, FLAGS, device)\n",
        "    val_epoch(epoch, model, criterion, val_loader, FLAGS, device)\n",
        "    \n",
        "    # save checkpoint\n",
        "    save_path = os.path.join(FLAGS.out_dir, f\"{FLAGS.model}_{FLAGS.task}_{epoch}.pt\")\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f\"Saved checkpoint: {save_path}\")\n",
        "\n",
        "\n",
        "################ 3. Test\n",
        "print('Begin test')\n",
        "predictions = run_test(model, test_loader, device)\n",
        "np.savetxt('pred.csv', predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 참고사항\n",
        "\n",
        "현재 설정한 모든 Epoch의 학습을 완료하면 이때까지 fitting된 모델 Weight로 테스트 셋에 대한 예측을 하게 됩니다. 따라서, Validation 결과상 Best 모델을 선택 해 추론을 하고 싶다면, 추가로 코드를 구현하셔야 합니다."
      ],
      "metadata": {
        "id": "XvOmYhLwFh1W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 결과 파일 제출\n",
        "\n",
        "1. 코랩 파일탭에서 생성된 \"pred.csv\"을 다운로드 합니다.\n",
        "1. https://aifactory.space/competition/submission/2106 에 접속합니다.\n",
        "1. \"pred.csv\"파일을 위 페이지에서 제출합니다.\n",
        "1. https://aifactory.space/competition/leaderboard/2106 리더보드에서 자신의 점수 및 순위를 확인합니다."
      ],
      "metadata": {
        "id": "ChLeBE1SXGoJ"
      }
    }
  ]
}