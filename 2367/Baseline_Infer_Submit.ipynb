{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+BFT3wUkRq00hg7yD02Q5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhlee93/AFCompetition/blob/main/2367/Baseline_Infer_Submit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 제출 코드에는 반드시 다음 코드가 실행 되어야합니다."
      ],
      "metadata": {
        "id": "NaUx5ZwidlZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 설치\n",
        "!pip install -qU aifactory\n",
        "!pip install -qU gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7mj3iZieXpd",
        "outputId": "e662e41e-d7cf-4893-94be-abbc0aafe0f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.6 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "gdown.download(url=\"https://drive.google.com/file/d/199E6lRrYGJdRtHxfwLPx2FZ2FjpDCTVt/view?usp=sharing\",\n",
        "               output='flower_photo.h5',\n",
        "               fuzzy=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "OFRVeKINhnrm",
        "outputId": "8fbbb193-e325-461f-cd7b-bd96a6f27b7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=199E6lRrYGJdRtHxfwLPx2FZ2FjpDCTVt\n",
            "To: /content/flower_photo.h5\n",
            "100%|██████████| 16.0M/16.0M [00:00<00:00, 138MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'flower_photo.h5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 여기서부터 작업을 진행해주세요."
      ],
      "metadata": {
        "id": "DOqk0WOne4Xz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJtXj-qQJO8e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 무작위성 통제"
      ],
      "metadata": {
        "id": "virJNNx8gRXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "gVDNGntTgTlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (180, 180, 3)\n",
        "classes = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
        "\n",
        "def load_model():\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    model = Sequential([\n",
        "        layers.experimental.preprocessing.Rescaling(1./255, input_shape=input_shape),\n",
        "        layers.Conv2D(filters=16, kernel_size=3, padding='same', activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(len(classes))\n",
        "    ])\n",
        "\n",
        "    model.load_weights('./flower_photo.h5')\n",
        "\n",
        "    # model.summary()\n",
        "    print('Success load model')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# 예측 함수는 AIF에서 제공하는 X_test의 입력 정보와, 메모리에 올라간 사전 학습 모델을 입력 받습니다.\n",
        "def predict(X_test_paths, model):\n",
        "    from tqdm import tqdm\n",
        "    my_result = []\n",
        "    for X_test_path in tqdm(X_test_paths):\n",
        "        image = Image.open(X_test_path).resize((180,180))\n",
        "        image = np.array(image, np.uint8) # (180, 180, 3)\n",
        "        image = np.expand_dims(image, axis=0) # (1, 180, 180, 3)\n",
        "        \n",
        "        pred_proba = model.predict(image, verbose=False)\n",
        "        pred_id = np.argmax(pred_proba, axis=1)[0]\n",
        "        pred_name = classes[pred_id]\n",
        "\n",
        "        my_result.append(pred_name)\n",
        "\n",
        "    return my_result\n",
        "\n",
        "# submit 함수는 AIF가 채점에 사용할 함수입니다.\n",
        "# 위에서 정의한 2개의 함수를 submit 함수를 통해 순차적으로 반환해주세요. (모델 로드 -> 예측)\n",
        "def submit():\n",
        "    return load_model, predict"
      ],
      "metadata": {
        "id": "WJFMLlLAiObH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "fno4T8abOugn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 이번 셀의 코드는 샘플 데이터로 코드가 정상적으로 작동하는지 확인하는 코드입니다.\n",
        "# # AIF가 채점 할 때에는 이 코드가 실행되지 않도록 if __name__ == \"__main__\": 조건 아래에 작성해주세요.\n",
        "# if __name__ == \"__main__\":\n",
        "#     # 샘플 데이터 다운로드\n",
        "#     from glob import glob\n",
        "#     !gdown https://drive.google.com/file/d/1WAkTFbo8ZyGPHQWC6ynhfAI6U2M1dZx0/view?usp=sharing --fuzzy --quiet\n",
        "#     !unzip samples.zip\n",
        "#     X_test_samples = glob('./samples/*.jpg') # 샘플 데이터 경로\n",
        "\n",
        "#     # 다음 코드는 참가자분께서 제출한 submit 함수를 활용해 AIF가 예측 및 채점하는 방식입니다.\n",
        "#     submit_load_model, submit_predict = submit()\n",
        "\n",
        "#     submit_model = submit_load_model()\n",
        "    \n",
        "#     y_pred = submit_predict(X_test_samples, submit_model)\n",
        "\n",
        "#     # score = f1_score(y_test, y_pred, average=\"macro\")\n",
        "#     # ..."
      ],
      "metadata": {
        "id": "4miKOsOzUP3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import aifactory.score as aif\n",
        "import ipynbname\n",
        "if __name__ == \"__main__\":\n",
        "    aif.submit(model_name=\"test submission\",\n",
        "               key='7511fd37-8e20-4591-b64c-00b2c4e5d2f1',\n",
        "               func=submit # submit function\n",
        "               )"
      ],
      "metadata": {
        "id": "V22PwCJihXjy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb655016-3996-4d9f-f2b0-d88b086d32b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file : fileId=1_RU5BQEYDT6EljkUhqtQUTRrQl-AZsBi\n",
            "Running on CoLab\n",
            "google colab\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_RU5BQEYDT6EljkUhqtQUTRrQl-AZsBi\n",
            "To: /content/task.ipynb\n",
            "100%|██████████| 6.49k/6.49k [00:00<00:00, 9.73MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "request id : 31 processing...\n",
            "score = 0.77047426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gdown.download(url=\"https://drive.google.com/file/d/1dmZIhtfnjyJPnZP8rsqdod_Ckf3pHD-P/view?usp=sharing\",\n",
        "               fuzzy=True)\n",
        "\n",
        "!unzip -q test.zip"
      ],
      "metadata": {
        "id": "LjFstp7TbPY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65f28b75-6688-436a-e430-77c955ba9275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=1dmZIhtfnjyJPnZP8rsqdod_Ckf3pHD-P\n",
            "From (redirected): https://drive.google.com/uc?id=1dmZIhtfnjyJPnZP8rsqdod_Ckf3pHD-P&confirm=t&uuid=202d76dc-4042-4976-b828-653647420945\n",
            "To: /content/test.zip\n",
            "100%|██████████| 66.3M/66.3M [00:01<00:00, 44.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = glob('./test/images/*.jpg')\n",
        "\n",
        "model = load_model()\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "results = predict(X_test, model)\n",
        "end = time.time()\n",
        "\n",
        "print(len(results))\n",
        "print('time:', end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hBpORoHoo-D",
        "outputId": "d92540e7-fc1b-4f68-d408-e0c061b57fac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success load model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1101/1101 [01:12<00:00, 15.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1101\n",
            "time: 72.93068504333496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cePqKX9Ho76E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}